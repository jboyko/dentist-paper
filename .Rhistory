v
expm(Q * phy$edge.length[desRows[desIndex]],
method = c("Ward77")) %*% liks[desNodes[desIndex],
]
v
-corHMM:::dev.corhmm(p=log(p), phy=phy, liks=data.for.likelihood.function$liks, Q=data.for.likelihood.function$Q, rate=data.for.likelihood.function$rate, root.p=root.p, rate.cat = rate.cat, order.test = FALSE, lewis.asc.bias = FALSE)
nb.node
nb.node
liks
traceback
traceback()
test <- ancRECON_slice(corhmm.obj, time_slice = c(10, 20, 30, 40), collapse = TRUE, ncores = 4)
data.for.likelihood.function$liks
data.for.likelihood.function$index.matrix
setdiff(1:dim(data.for.likelihood.function$Q)[2], drop.states)
state.index
taxon.index
data.for.likelihood.function$liks[taxon.index,]
data.for.likelihood.function$liks[taxon.index,]
data.for.likelihood.function$liks
comp
p
anc
k.rates
print(Q)
rowSums(Q)
p
rate
corhmm.obj$solution[!is.na(corhmm.obj$solution)]
?ancRECON
#Now lets calculate some marginals!
p <- sapply(1:max(corhmm.obj$index.mat, na.rm = TRUE), function(x) na.omit(c(corhmm.obj$solution))[na.omit(c(corhmm.obj$index.mat) == x)][1])
all_recon
all_recon <- mclapply(all_trees, function(x) GetEdgeMarginal(p=p, phy=x, data=new.data, rate.mat=corhmm.obj$index.mat, rate.cat=corhmm.obj$rate.cat, ntraits=ntraits, root.p=corhmm.obj$root.p, model = "ARD", collapse = collapse), mc.cores = ncores)
# the main function for doing a marginal time slice reconstruction
ancRECON_slice <- function(corhmm.obj, time_slice, collapse=TRUE, ncores = 1){
if(max(time_slice) >= max(branching.times(corhmm.obj$phy))){
stop("time_slice must be less than the maximum branching time of the tree")
}
# get the fake node locations for the reconstruction based on the time slice
to_recon <- sapply(time_slice, function(x) getNodePlacementsForSlice(phy, x))
to_recon <- (apply(to_recon, 2, function(x) do.call(cbind, x)))
for(i in seq_len(length(time_slice))){
to_recon[[i]] <- cbind(time_slice = time_slice[i], to_recon[[i]])
}
to_recon <- do.call(rbind, to_recon)
# create a dummy tip and dummy data
tip.name <- "FakeyMcFakerson"
tip <- list(edge=matrix(c(2,1),1,2), tip.label=tip.name, edge.length=0, Nnode=1)
class(tip) <- "phylo"
new.data <- corhmm.obj$data.legend
new.data[,1] <- as.character(new.data[,1])
new.data <- rbind(new.data, "?")
new.data[nrow(new.data), 1] <- "FakeyMcFakerson"
ntraits <- max(as.numeric(corhmm.obj$data.legend$d))
# get all the new phys
print(paste0("Reconstructing ", nrow(to_recon), " nodes for ", length(time_slice), " time slices..."))
all_trees <- apply(to_recon, 1, function(x) bind.tree(corhmm.obj$phy, tip, x[2], x[3]))
#Now lets calculate some marginals!
p <- sapply(1:max(corhmm.obj$index.mat, na.rm = TRUE), function(x) na.omit(c(corhmm.obj$solution))[na.omit(c(corhmm.obj$index.mat) == x)][1])
all_recon <- lapply(all_trees, function(x) GetEdgeMarginal(p=p, phy=x, data=new.data, rate.mat=corhmm.obj$index.mat, rate.cat=corhmm.obj$rate.cat, ntraits=ntraits, root.p=corhmm.obj$root.p, model = "ARD", collapse = collapse))
all_recon <-  do.call(rbind, all_recon)
colnames(all_recon) <- colnames(corhmm.obj$solution)
out <- cbind(to_recon, all_recon)
return(out)
}
plot_slice_recon <- function(phy, slice_df, col=NULL){
plot(phy, show.tip.label = FALSE)
lastPP <- get("last_plot.phylo", envir = .PlotPhyloEnv)
node <- (lastPP$Ntip + 1):length(lastPP$xx)
XX <- lastPP$xx[node]
YY <- lastPP$yy[node]
for(i in 1:nrow(slice_df)){
focal <- slice_df[i,]
xx <- lastPP$xx[focal[2]] - focal[3]
yy <- lastPP$yy[focal[2]]
pp <- focal[-c(1:3)]
floating.pie.asp(xx, yy, pp, radius = 0.5, col = col)
}
}
# testing
library(corHMM)
library(parallel)
library(viridis)
test <- ancRECON_slice(corhmm.obj, time_slice = c(10, 20, 30, 40), collapse = TRUE, ncores = 4)
p
print(Q)
test <- ancRECON_slice(corhmm.obj, time_slice = c(10, 20, 30, 40), collapse = TRUE, ncores = 4)
v
fixer
v * fixer
fixer
corhmm.obj$phy$node.label <- NULL
# the main function for doing a marginal time slice reconstruction
ancRECON_slice <- function(corhmm.obj, time_slice, collapse=TRUE, ncores = 1){
if(max(time_slice) >= max(branching.times(corhmm.obj$phy))){
stop("time_slice must be less than the maximum branching time of the tree")
}
# get the fake node locations for the reconstruction based on the time slice
to_recon <- sapply(time_slice, function(x) getNodePlacementsForSlice(phy, x))
to_recon <- (apply(to_recon, 2, function(x) do.call(cbind, x)))
for(i in seq_len(length(time_slice))){
to_recon[[i]] <- cbind(time_slice = time_slice[i], to_recon[[i]])
}
to_recon <- do.call(rbind, to_recon)
# create a dummy tip and dummy data
tip.name <- "FakeyMcFakerson"
tip <- list(edge=matrix(c(2,1),1,2), tip.label=tip.name, edge.length=0, Nnode=1)
class(tip) <- "phylo"
new.data <- corhmm.obj$data.legend
new.data[,1] <- as.character(new.data[,1])
new.data <- rbind(new.data, "?")
new.data[nrow(new.data), 1] <- "FakeyMcFakerson"
ntraits <- max(as.numeric(corhmm.obj$data.legend$d))
# get all the new phys
print(paste0("Reconstructing ", nrow(to_recon), " nodes for ", length(time_slice), " time slices..."))
corhmm.obj$phy$node.label <- NULL
all_trees <- apply(to_recon, 1, function(x) bind.tree(corhmm.obj$phy, tip, x[2], x[3]))
#Now lets calculate some marginals!
p <- sapply(1:max(corhmm.obj$index.mat, na.rm = TRUE), function(x) na.omit(c(corhmm.obj$solution))[na.omit(c(corhmm.obj$index.mat) == x)][1])
all_recon <- lapply(all_trees, function(x) GetEdgeMarginal(p=p, phy=x, data=new.data, rate.mat=corhmm.obj$index.mat, rate.cat=corhmm.obj$rate.cat, ntraits=ntraits, root.p=corhmm.obj$root.p, model = "ARD", collapse = collapse))
all_recon <-  do.call(rbind, all_recon)
colnames(all_recon) <- colnames(corhmm.obj$solution)
out <- cbind(to_recon, all_recon)
return(out)
}
test <- ancRECON_slice(corhmm.obj, time_slice = c(10, 20, 30, 40), collapse = TRUE, ncores = 4)
undebug(corHMM:::dev.corhmm)
#Marginal reconstruction function for our custom corHMM
GetEdgeMarginal <- function(p, phy, data, rate.mat, rate.cat, ntraits, model, root.p, collapse = TRUE){
nb.tip <- length(phy$tip.label)
nb.node <- phy$Nnode
data.for.likelihood.function <- corHMM:::rate.cat.set.corHMM.JDB(phy=phy, data=data, rate.cat=rate.cat, ntraits = ntraits, model = model, collapse = collapse)
if(!is.null(rate.mat)){
rate <- rate.mat
data.for.likelihood.function$np <- max(rate, na.rm=TRUE)
rate[is.na(rate)]=max(rate, na.rm=TRUE)+1
data.for.likelihood.function$rate <- rate
data.for.likelihood.function$index.matrix <- rate.mat
## for precursor type models ##
col.sums <- which(colSums(rate.mat, na.rm=TRUE) == 0)
row.sums <- which(rowSums(rate.mat, na.rm=TRUE) == 0)
drop.states <- col.sums[which(col.sums == row.sums)]
if(length(drop.states > 0)){
data.for.likelihood.function$liks[,drop.states] <- 0
}
###############################
}else{
drop.states <- NULL
}
phy <- reorder(phy, "pruningwise")
nodes <- unique(phy$edge[,1])
taxon.index <- grep("FakeyMcFakerson", x=phy$tip.label)
marginal.probs.tmp <- numeric(dim(data.for.likelihood.function$Q)[2])
nstates = which(!data.for.likelihood.function$liks[taxon.index,] == 0)
states.keep = data.for.likelihood.function$liks[taxon.index,]
for(state.index in setdiff(1:dim(data.for.likelihood.function$Q)[2], drop.states)){
data.for.likelihood.function$liks[taxon.index,] = 0
data.for.likelihood.function$liks[taxon.index,state.index] = 1
# print(data.for.likelihood.function$liks)
marginal.probs.tmp[state.index] <- -corHMM:::dev.corhmm(p=log(p), phy=phy, liks=data.for.likelihood.function$liks, Q=data.for.likelihood.function$Q, rate=data.for.likelihood.function$rate, root.p=root.p, rate.cat = rate.cat, order.test = FALSE, lewis.asc.bias = FALSE)
}
data.for.likelihood.function$liks[taxon.index,] <- states.keep
best.probs <- max(marginal.probs.tmp[nstates])
marginal.probs.rescaled <- marginal.probs.tmp[nstates] - best.probs
marginal.probs.final <- exp(marginal.probs.rescaled) / sum(exp(marginal.probs.rescaled))
return(marginal.probs.final)
}
# creates a table for locating where to add nodes. first column is the node index (tip or internal). second column is the time period from the node to add
getNodePlacementsForSlice <- function(phy, time_slice){
to_add <- data.frame(node = 1:length(phy$tip.label), position = time_slice)
nodes_younger_than_slice <- branching.times(phy)[branching.times(phy) < time_slice]
node_to_add <- data.frame(node = as.numeric(names(nodes_younger_than_slice)), position = time_slice - nodes_younger_than_slice)
to_add <- rbind(to_add, node_to_add)
edge_lengths <- phy$edge.length[match(to_add[,1], phy$edge[,2])]
to_add <- to_add[edge_lengths - to_add[,2] > 0,] # exludes nodes too far away
return(to_add)
}
# the main function for doing a marginal time slice reconstruction
ancRECON_slice <- function(corhmm.obj, time_slice, collapse=TRUE, ncores = 1){
if(max(time_slice) >= max(branching.times(corhmm.obj$phy))){
stop("time_slice must be less than the maximum branching time of the tree")
}
# get the fake node locations for the reconstruction based on the time slice
to_recon <- sapply(time_slice, function(x) getNodePlacementsForSlice(phy, x))
to_recon <- (apply(to_recon, 2, function(x) do.call(cbind, x)))
for(i in seq_len(length(time_slice))){
to_recon[[i]] <- cbind(time_slice = time_slice[i], to_recon[[i]])
}
to_recon <- do.call(rbind, to_recon)
# create a dummy tip and dummy data
tip.name <- "FakeyMcFakerson"
tip <- list(edge=matrix(c(2,1),1,2), tip.label=tip.name, edge.length=0, Nnode=1)
class(tip) <- "phylo"
new.data <- corhmm.obj$data.legend
new.data[,1] <- as.character(new.data[,1])
new.data <- rbind(new.data, "?")
new.data[nrow(new.data), 1] <- "FakeyMcFakerson"
ntraits <- max(as.numeric(corhmm.obj$data.legend$d))
# get all the new phys
print(paste0("Reconstructing ", nrow(to_recon), " nodes for ", length(time_slice), " time slices..."))
corhmm.obj$phy$node.label <- NULL
all_trees <- apply(to_recon, 1, function(x) bind.tree(corhmm.obj$phy, tip, x[2], x[3]))
#Now lets calculate some marginals!
p <- sapply(1:max(corhmm.obj$index.mat, na.rm = TRUE), function(x) na.omit(c(corhmm.obj$solution))[na.omit(c(corhmm.obj$index.mat) == x)][1])
all_recon <- lapply(all_trees, function(x) GetEdgeMarginal(p=p, phy=x, data=new.data, rate.mat=corhmm.obj$index.mat, rate.cat=corhmm.obj$rate.cat, ntraits=ntraits, root.p=corhmm.obj$root.p, model = "ARD", collapse = collapse))
all_recon <-  do.call(rbind, all_recon)
colnames(all_recon) <- colnames(corhmm.obj$solution)
out <- cbind(to_recon, all_recon)
return(out)
}
plot_slice_recon <- function(phy, slice_df, col=NULL){
plot(phy, show.tip.label = FALSE)
lastPP <- get("last_plot.phylo", envir = .PlotPhyloEnv)
node <- (lastPP$Ntip + 1):length(lastPP$xx)
XX <- lastPP$xx[node]
YY <- lastPP$yy[node]
for(i in 1:nrow(slice_df)){
focal <- slice_df[i,]
xx <- lastPP$xx[focal[2]] - focal[3]
yy <- lastPP$yy[focal[2]]
pp <- focal[-c(1:3)]
floating.pie.asp(xx, yy, pp, radius = 0.5, col = col)
}
}
# testing
library(corHMM)
library(parallel)
library(viridis)
data(primates)
phy <- multi2di(primates[[1]])
data <- primates[[2]]
test <- ancRECON_slice(corhmm.obj, time_slice = c(10, 20, 30, 40), collapse = TRUE, ncores = 4)
plot_slice_recon(phy, test, col = viridis(5))
plot_slice_recon(phy, test, col = viridis(6))
library(corHMM)
?ancRECON_slice
library(viridis)
data(primates)
phy <- multi2di(primates[[1]])
data <- primates[[2]]
corhmm.obj <- corHMM(phy = phy, data = data, rate.cat = 1)
test <- ancRECON_slice(corhmm.obj, time_slice = c(1, 10, 20, 30, 40, 49), collapse = TRUE, ncores = 4)
corHMM:::plot_slice_recon(phy, test, col = viridis(3))
test
head(test)
time_slice <- df[, "time_slice"]  # Extract the time_slice column
df <- ancRECON_slice(corhmm.obj, time_slice = c(1, 10, 20, 30, 40, 49), collapse = TRUE, ncores = 4)
time_slice <- df[, "time_slice"]  # Extract the time_slice column
probabilities <- df[, c("(1,R1)", "(2,R1)", "(3,R1)")]  # Extract the probability columns
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
library(dplyr)
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
library(tidyverse)
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
df
time_slice <- df[, "time_slice"]  # Extract the time_slice column
probabilities <- df[, c("(1,R1)", "(2,R1)", "(3,R1)")]  # Extract the probability columns
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
pivot_longer
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
df
df_long <- df[,-c(2,3)] %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
df[,-c(2,3)]
df_long <- df %>%
pivot_longer(cols = c("(1,R1)", "(2,R1)", "(3,R1)"), names_to = "Probability", values_to = "Value")
df_long <- data.frame(
time_slice = rep(time_slice, each = ncol(probabilities)),
Probability = rep(colnames(probabilities), times = nrow(probabilities)),
Value = as.vector(probabilities)
)
ggplot(df_long, aes(x = time_slice, y = Value, color = Probability)) +
geom_line() +
labs(x = "Time Slice", y = "Probability") +
scale_color_manual(values = c("(1,R1)" = "red", "(2,R1)" = "blue", "(3,R1)" = "green")) +
theme_minimal()
df_long
df
?aggregate(df)
df
df <- as.data.frame(df)
df$time_slice
df[,-c(1:3)
df[,-c(1:3)]
df[,-c(1:3)]
aggregate(df[,-c(1:3)], by = list(df$time_slice), mean)
aggregate(df[,-c(1:3)], by = list(df$time_slice), mean)
df_summ <- aggregate(df[,-c(1:3)], by = list(df$time_slice), mean)
df_summ
df_summ <- aggregate(df[,-c(1:3)], by = list(df$time_slice), sum)
df_summ
install.packages("networkD3")  # Install the networkD3 package if not already installed
library(networkD3)
time_points <- df$Group.1
df_summ
time_points <- df_summ$Group.1
probabilities <- df_summ[, c("(1,R1)", "(2,R1)", "(3,R1)")]
time_points
probabilities
create_sankey_plot <- function(time_slice, probabilities) {
# Create a data frame for the Sankey plot
sankey_data <- data.frame(
from = rep("Group", each = nrow(probabilities)),
to = colnames(probabilities),
value = as.vector(probabilities)
)
# Create the Sankey plot
sankeyPlot(
Links = sankey_data,
Nodes = data.frame(name = unique(c(sankey_data$from, sankey_data$to))),
Source = "from",
Target = "to",
Value = "value",
NodeID = "name",
sinksRight = FALSE
)
}
for (i in 1:length(time_points)) {
plot_title <- paste("Time Point:", time_points[i])
plot <- create_sankey_plot(time_points[i], probabilities[i, ])
# Display the Sankey plot
cat(paste0("<h3>", plot_title, "</h3>"))
print(plot)
}
library(hisse)
simulated.result <- SimulateHisse(c(.3, .1), c(.1, 0),
matrix(c(NA, 0.2, .3, NA), nrow=2), max.taxa=35, x0=1)
par(mfcol=c(1,2))
plot(SimToPhylo(simulated.result$results, include.extinct=TRUE))
plot(SimToPhylo(simulated.result$results, include.extinct=FALSE))
simulated.result
setwd("~/dentist-paper/")
require(dentist)
require(corHMM)
require(parallel)
data(primates)
phy <- multi2di(primates[[1]])
phy$edge.length <- phy$edge.length + 1e-4
data <- primates[[2]]
data <- data[,c(1,2)]
MK_3state <- corHMM(phy = phy, data = data, rate.cat = 1)
MK_3state
fn_corHMM <- function(par, phy, data, rate.cat){
corhmm_fit <- corHMM(phy = phy, data = data, rate.cat = 1, p = par)
loglik <- corhmm_fit$loglik
neg_loglik <- -loglik
return(neg_loglik)
}
quick_fit <- function(phy, dat){
dat <- data.frame(sp = names(dat), d = dat)
corhmm_fit <- corHMM(phy = phy, data = dat, rate.cat = 1, node.states = "none")
return(corhmm_fit)
}
# parametric boostrap approach
anc <- MK_3state$states[1,]
Q <- MK_3state$solution
diag(Q) <- -rowSums(Q, na.rm = TRUE)
data <- lapply(1:1000, function(x) corHMM:::simMarkov(phy, Q, anc)$TipStates)
# fits <- mclapply(data, function(x) try(quick_fit(phy, x)), mc.cores = 10)
# fits <- fits[unlist(lapply(fits, class)) == "corhmm"] # remove univariate simulations
# save(fits, file = "saves/corhmm-example-fits.rsave")
load(file = "saves/corhmm-example-fits.rsave")
refit_pars <- do.call(rbind, lapply(fits, function(x) x$solution[!is.na(x$solution)]))
# using dentist
par <- c(MK_3state$solution[!is.na(MK_3state$solution)])
names(par) <- c("rate_21", "rate_12")
data <- primates[[2]]
data <- data[,c(1,2)]
# corhmm_example_jnt <- dent_walk(par, fn_corHMM, -MK_3state$loglik, phy = phy, data = data, rate.cat = 1, nsteps = 2000)
# save(corhmm_example_jnt, file = "saves/corhmm-example-corhmm_example_jnt.rsave")
load("saves/corhmm-example-corhmm_example_jnt.rsave")
# comparison
corhmm_example_jnt
quantile(refit_pars[,1], c(.025, .975))
quantile(refit_pars[,2], c(.025, .975))
mean(refit_pars[,1])
median(refit_pars[,1])
par
mean(refit_pars[,2])
median(refit_pars[,2])
source("~/dentist-paper/code/corhmm-example.R", echo=TRUE)
par
mean(refit_pars[,2])
median(refit_pars[,2])
corhmm_example_jnt
rm(list=ls())
setwd("~/2022_dentist/")
set.seed(1)
require(diversitree)
require(dentist)
convert2Lambda <- function(pars){
if(is.na(pars[1])){
focal_pars <- sample(which(!is.na(pars)), size = 2, replace = FALSE)
if(2 %in% focal_pars & 3 %in% focal_pars){
# mu and div
lambda <- pars[2] + pars[3]
}
if(2 %in% focal_pars & 4 %in% focal_pars){
# mu and turn
lambda <- pars[4] - pars[2]
}
if(2 %in% focal_pars & 5 %in% focal_pars){
# mu and ef
lambda <- pars[2]/pars[5]
}
if(3 %in% focal_pars & 4 %in% focal_pars){
# div and turn
lambda <- (pars[3]+pars[4])/2
}
if(3 %in% focal_pars & 5 %in% focal_pars){
# div and ef
lambda <- pars[3]/(1-pars[5])
}
if(4 %in% focal_pars & 5 %in% focal_pars){
# turn and ef
lambda <- pars[4]/(1+pars[5])
}
}else{
lambda <- pars[1]
}
return(lambda)
}
convert2Mu <- function(pars){
if(is.na(pars[2])){
focal_pars <- sample(which(!is.na(pars)), size = 2, replace = FALSE)
if(1 %in% focal_pars & 3 %in% focal_pars){
# lambda and div
mu <- pars[1] - pars[3]
}
if(1 %in% focal_pars & 4 %in% focal_pars){
# lambda and turn
mu <- pars[4] - pars[1]
}
if(1 %in% focal_pars & 5 %in% focal_pars){
# lambda and ef
mu <- pars[1]*pars[5]
}
if(3 %in% focal_pars & 4 %in% focal_pars){
# div and turn
mu <- (pars[4] - pars[3])/2
}
if(3 %in% focal_pars & 5 %in% focal_pars){
# div and ef
mu <- (pars[3]*pars[5])/(1-pars[5])
}
if(4 %in% focal_pars & 5 %in% focal_pars){
# turn and ef
mu <- (pars[4]*pars[5])/(1+pars[5])
}
}else{
mu <- pars[2]
}
return(mu)
}
convertBetweenPars <- function(pars){
# pars <- c("lambda", "mu", "net.div", "turn", "ef")
if(length(which(!is.na(pars))) >= 3){
warning("More than 2 paramaters are specified. Randomly choosing 2 for the calculations.")
}
if(is.na(pars[1])){
lambda <- convert2Lambda(pars)
}else{
lambda <- pars[1]
}
if(is.na(pars[2])){
mu <- convert2Mu(pars)
}else{
mu <- pars[2]
}
net.div <- lambda - mu
turn <- lambda + mu
ef <- mu/lambda
out <- c(lambda=lambda, mu=mu, net.div=net.div, turn=turn, ef=ef)
if(!setequal(round(out[which(!is.na(pars))], 5), round(pars[which(!is.na(pars))], 5))){
stop("An error occured because the calculated output doesn't match the input. Please check that your input parameters can be combined in a way that is possible.")
}
return(out)
}
## Simulate a tree under a constant rates birth-death model and look at
## the maximum likelihood speciation/extinction parameters:
phy <- trees(c(1, .5), "bd", max.taxa=10)[[1]]
lik <- make.bd(phy)
## By default, optimisation gives a lambda close to 0.1 and extremely
## small mu:
fit <- find.mle(lik, c(1, .5))
# remember the change the output of the function to negative loglik
bd_fn <- function(par, phy){
lik <- make.bd(phy)
LnLik <- lik(par)
return(-LnLik)
}
# dent_res_10 <- dent_walk(par = coef(fit), bd_fn, best_neglnL = -fit$lnLik, nsteps = 1000, phy=phy, sd = c(1, 0.5))
#save(dent_res_10, file="saves/dent_res_10.Rsave")
load("saves/dent_res_10.Rsave")
fit
coef(fit)
# a quick parametric bootstrap
library(TreeSim)
age = max(branching.times(phy))
taxa = length(phy$tip.label)
many_trees <- sim.bd.taxa.age(n = taxa, numbsim = 1000, lambda = fit$par[1], mu = fit$par[2], age = age)
many_fits <- lapply(many_trees, function(x) find.mle(make.bd(x), c(1,.5)))
many_fits <- do.call(rbind, lapply(many_fits, function(x) x$par))
many_fits
colMeans(many_fits)
coef(fit)
